{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif, RFE\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('roe_class.csv', thousands=',', encoding = \"EUC-KR\")\n",
    "data = data[~data.isin([np.nan, np.inf, -np.inf, '#NAME?','NaN']).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\numpy\\lib\\function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sales</th>\n",
       "      <th>roe</th>\n",
       "      <th>current_liabilities_to_assets</th>\n",
       "      <th>non_current_liabilities_to_assets</th>\n",
       "      <th>cost_of_goods_sold_to_sales</th>\n",
       "      <th>gross_profit_to_sales</th>\n",
       "      <th>selling_and_administrative_expenses_to_sales</th>\n",
       "      <th>labor_costs_to_sales</th>\n",
       "      <th>rnd_costs_to_sales</th>\n",
       "      <th>advertisement_cost_to_sales</th>\n",
       "      <th>selling_costs_to_sales</th>\n",
       "      <th>administrative_costs_to_sales</th>\n",
       "      <th>rent_to_sales</th>\n",
       "      <th>operating_income_to_sales</th>\n",
       "      <th>net_income_to_sales</th>\n",
       "      <th>sales_growth</th>\n",
       "      <th>cost_of_goods_sold_growth</th>\n",
       "      <th>sna_expenses_growth</th>\n",
       "      <th>future_roe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27396.000000</td>\n",
       "      <td>27358.000000</td>\n",
       "      <td>27396.000000</td>\n",
       "      <td>26446.000000</td>\n",
       "      <td>26446.000000</td>\n",
       "      <td>26928.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>26436.000000</td>\n",
       "      <td>26436.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>27373.000000</td>\n",
       "      <td>27313.000000</td>\n",
       "      <td>26147.000000</td>\n",
       "      <td>27387.000000</td>\n",
       "      <td>27396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2008.763469</td>\n",
       "      <td>8.006041</td>\n",
       "      <td>0.051723</td>\n",
       "      <td>0.326517</td>\n",
       "      <td>0.124569</td>\n",
       "      <td>0.750506</td>\n",
       "      <td>0.261669</td>\n",
       "      <td>0.276435</td>\n",
       "      <td>0.109005</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>0.070706</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.037379</td>\n",
       "      <td>0.088244</td>\n",
       "      <td>0.109663</td>\n",
       "      <td>0.111829</td>\n",
       "      <td>0.120044</td>\n",
       "      <td>0.043001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.775528</td>\n",
       "      <td>0.734475</td>\n",
       "      <td>2.279687</td>\n",
       "      <td>0.194307</td>\n",
       "      <td>0.201387</td>\n",
       "      <td>0.281754</td>\n",
       "      <td>0.295096</td>\n",
       "      <td>5.288560</td>\n",
       "      <td>3.452931</td>\n",
       "      <td>0.347428</td>\n",
       "      <td>0.226871</td>\n",
       "      <td>0.073079</td>\n",
       "      <td>1.301683</td>\n",
       "      <td>0.044099</td>\n",
       "      <td>7.169359</td>\n",
       "      <td>14.298708</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>0.403889</td>\n",
       "      <td>2.244590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>3.480438</td>\n",
       "      <td>-137.910987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025984</td>\n",
       "      <td>-12.321316</td>\n",
       "      <td>-24.586099</td>\n",
       "      <td>-13.417507</td>\n",
       "      <td>-0.001408</td>\n",
       "      <td>-1.154212</td>\n",
       "      <td>-2.094313</td>\n",
       "      <td>-0.008789</td>\n",
       "      <td>-1.610671</td>\n",
       "      <td>-863.096262</td>\n",
       "      <td>-344.957143</td>\n",
       "      <td>-7.242915</td>\n",
       "      <td>-7.746389</td>\n",
       "      <td>-7.557424</td>\n",
       "      <td>-137.910987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>11.359252</td>\n",
       "      <td>268.047564</td>\n",
       "      <td>8.779681</td>\n",
       "      <td>19.495058</td>\n",
       "      <td>13.321316</td>\n",
       "      <td>1.025984</td>\n",
       "      <td>864.095931</td>\n",
       "      <td>568.624876</td>\n",
       "      <td>30.458631</td>\n",
       "      <td>37.251737</td>\n",
       "      <td>4.553302</td>\n",
       "      <td>208.334105</td>\n",
       "      <td>4.809461</td>\n",
       "      <td>713.959946</td>\n",
       "      <td>2165.518028</td>\n",
       "      <td>7.172682</td>\n",
       "      <td>11.937225</td>\n",
       "      <td>11.158938</td>\n",
       "      <td>268.047564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year         sales           roe  \\\n",
       "count  27396.000000  27358.000000  27396.000000   \n",
       "mean    2008.763469      8.006041      0.051723   \n",
       "std        4.775528      0.734475      2.279687   \n",
       "min     2000.000000      3.480438   -137.910987   \n",
       "25%     2005.000000           NaN      0.009957   \n",
       "50%     2009.000000           NaN      0.073370   \n",
       "75%     2013.000000           NaN      0.152979   \n",
       "max     2016.000000     11.359252    268.047564   \n",
       "\n",
       "       current_liabilities_to_assets  non_current_liabilities_to_assets  \\\n",
       "count                   26446.000000                       26446.000000   \n",
       "mean                        0.326517                           0.124569   \n",
       "std                         0.194307                           0.201387   \n",
       "min                         0.000000                           0.000000   \n",
       "25%                              NaN                                NaN   \n",
       "50%                              NaN                                NaN   \n",
       "75%                              NaN                                NaN   \n",
       "max                         8.779681                          19.495058   \n",
       "\n",
       "       cost_of_goods_sold_to_sales  gross_profit_to_sales  \\\n",
       "count                 26928.000000           27373.000000   \n",
       "mean                      0.750506               0.261669   \n",
       "std                       0.281754               0.295096   \n",
       "min                      -0.025984             -12.321316   \n",
       "25%                            NaN                    NaN   \n",
       "50%                            NaN                    NaN   \n",
       "75%                            NaN                    NaN   \n",
       "max                      13.321316               1.025984   \n",
       "\n",
       "       selling_and_administrative_expenses_to_sales  labor_costs_to_sales  \\\n",
       "count                                  27373.000000          27373.000000   \n",
       "mean                                       0.276435              0.109005   \n",
       "std                                        5.288560              3.452931   \n",
       "min                                      -24.586099            -13.417507   \n",
       "25%                                             NaN                   NaN   \n",
       "50%                                             NaN                   NaN   \n",
       "75%                                             NaN                   NaN   \n",
       "max                                      864.095931            568.624876   \n",
       "\n",
       "       rnd_costs_to_sales  advertisement_cost_to_sales  \\\n",
       "count        27373.000000                 27373.000000   \n",
       "mean             0.024978                     0.010838   \n",
       "std              0.347428                     0.226871   \n",
       "min             -0.001408                    -1.154212   \n",
       "25%                   NaN                          NaN   \n",
       "50%                   NaN                          NaN   \n",
       "75%                   NaN                          NaN   \n",
       "max             30.458631                    37.251737   \n",
       "\n",
       "       selling_costs_to_sales  administrative_costs_to_sales  rent_to_sales  \\\n",
       "count            26436.000000                   26436.000000   27373.000000   \n",
       "mean                 0.032396                       0.070706       0.006857   \n",
       "std                  0.073079                       1.301683       0.044099   \n",
       "min                 -2.094313                      -0.008789      -1.610671   \n",
       "25%                       NaN                            NaN            NaN   \n",
       "50%                       NaN                            NaN            NaN   \n",
       "75%                       NaN                            NaN            NaN   \n",
       "max                  4.553302                     208.334105       4.809461   \n",
       "\n",
       "       operating_income_to_sales  net_income_to_sales  sales_growth  \\\n",
       "count               27373.000000         27373.000000  27313.000000   \n",
       "mean                    0.037379             0.088244      0.109663   \n",
       "std                     7.169359            14.298708      0.445100   \n",
       "min                  -863.096262          -344.957143     -7.242915   \n",
       "25%                          NaN                  NaN           NaN   \n",
       "50%                          NaN                  NaN           NaN   \n",
       "75%                          NaN                  NaN           NaN   \n",
       "max                   713.959946          2165.518028      7.172682   \n",
       "\n",
       "       cost_of_goods_sold_growth  sna_expenses_growth    future_roe  \n",
       "count               26147.000000         27387.000000  27396.000000  \n",
       "mean                    0.111829             0.120044      0.043001  \n",
       "std                     0.475919             0.403889      2.244590  \n",
       "min                    -7.746389            -7.557424   -137.910987  \n",
       "25%                          NaN                  NaN      0.006770  \n",
       "50%                          NaN                  NaN      0.068568  \n",
       "75%                          NaN                  NaN      0.143497  \n",
       "max                    11.937225            11.158938    268.047564  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.set_index(['code','year'], inplace=True)\n",
    "# data_dummy = pd.get_dummies(data['sector'])\n",
    "# data_merged = pd.merge(data.reset_index(),data_dummy.reset_index(), how='inner', on=['code','year'])\n",
    "# data_merged.reset_index(inplace=True, drop=True)\n",
    "data_merged = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dn', 'up'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(data_merged['roe_class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged['roe_class_PN'] = np.where(data_merged['roe_class'].isin(['PU','NP','NU']),'UP','DOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_merged['updown'] = np.where(data_merged['future_roe'] > data_merged['roe'], 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_label = pd.unique(data_merged['roe_class_PN'])\n",
    "# le = LabelEncoder().fit(class_label)\n",
    "# y = le.transform(data_merged['roe_class_PN'])\n",
    "y = data_merged['roe_class']\n",
    "\n",
    "X = data_merged.reset_index(drop=True).drop(['code','year','sector','roe_class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-238699faad35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mselection_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rfe' is not defined"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='ovr')\n",
    "selection_model = RFE(model, 10)\n",
    "X_new = selection_model.fit_transform(X, y)\n",
    "X.columns[selection_model.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-3f4f68bd5984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mselection_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselection_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \"\"\"\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    541\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    420\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 43\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "selection_model = SelectKBest(f_classif, k=5)\n",
    "X_new = selection_model.fit_transform(X, y)\n",
    "X.columns[selection_model.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roe</th>\n",
       "      <th>dividends_to_assets</th>\n",
       "      <th>short_term_borrowings_to_assets</th>\n",
       "      <th>cost_of_goods_sold_to_sales</th>\n",
       "      <th>non_operating_expenses_to_sales</th>\n",
       "      <th>taxes_from_continuing_operation_to_sales</th>\n",
       "      <th>operating_cash_flow_to_sales</th>\n",
       "      <th>average_total_equity_growth</th>\n",
       "      <th>cost_of_goods_sold_growth</th>\n",
       "      <th>non_operating_revenue_growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "      <td>20413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.059617</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.772704</td>\n",
       "      <td>0.062710</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>0.061929</td>\n",
       "      <td>0.148603</td>\n",
       "      <td>0.123439</td>\n",
       "      <td>0.211275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240575</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.119888</td>\n",
       "      <td>0.167264</td>\n",
       "      <td>0.099840</td>\n",
       "      <td>0.025174</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>0.258743</td>\n",
       "      <td>0.365712</td>\n",
       "      <td>0.664096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.364547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-0.373153</td>\n",
       "      <td>-2.310375</td>\n",
       "      <td>-0.992862</td>\n",
       "      <td>-0.986064</td>\n",
       "      <td>-0.998892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.705288</td>\n",
       "      <td>0.019142</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.026524</td>\n",
       "      <td>-0.028507</td>\n",
       "      <td>-0.208175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.076274</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.085639</td>\n",
       "      <td>0.817108</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.059684</td>\n",
       "      <td>0.099894</td>\n",
       "      <td>0.081607</td>\n",
       "      <td>0.107325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.149932</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.187016</td>\n",
       "      <td>0.883314</td>\n",
       "      <td>0.066203</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>0.120237</td>\n",
       "      <td>0.223167</td>\n",
       "      <td>0.215812</td>\n",
       "      <td>0.510184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.876161</td>\n",
       "      <td>0.098483</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>1.491469</td>\n",
       "      <td>1.476710</td>\n",
       "      <td>0.336095</td>\n",
       "      <td>2.076602</td>\n",
       "      <td>4.370252</td>\n",
       "      <td>11.937225</td>\n",
       "      <td>5.961739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                roe  dividends_to_assets  short_term_borrowings_to_assets  \\\n",
       "count  20413.000000         20413.000000                     20413.000000   \n",
       "mean       0.059617             0.007518                         0.117100   \n",
       "std        0.240575             0.010975                         0.119888   \n",
       "min       -4.364547             0.000000                         0.000000   \n",
       "25%        0.016743             0.000000                         0.009737   \n",
       "50%        0.076274             0.003573                         0.085639   \n",
       "75%        0.149932             0.011124                         0.187016   \n",
       "max        1.876161             0.098483                         0.765049   \n",
       "\n",
       "       cost_of_goods_sold_to_sales  non_operating_expenses_to_sales  \\\n",
       "count                 20413.000000                     20413.000000   \n",
       "mean                      0.772704                         0.062710   \n",
       "std                       0.167264                         0.099840   \n",
       "min                       0.000491                         0.000161   \n",
       "25%                       0.705288                         0.019142   \n",
       "50%                       0.817108                         0.035861   \n",
       "75%                       0.883314                         0.066203   \n",
       "max                       1.491469                         1.476710   \n",
       "\n",
       "       taxes_from_continuing_operation_to_sales  operating_cash_flow_to_sales  \\\n",
       "count                              20413.000000                  20413.000000   \n",
       "mean                                   0.013074                      0.061929   \n",
       "std                                    0.025174                      0.136612   \n",
       "min                                   -0.373153                     -2.310375   \n",
       "25%                                    0.000710                      0.007306   \n",
       "50%                                    0.009805                      0.059684   \n",
       "75%                                    0.022228                      0.120237   \n",
       "max                                    0.336095                      2.076602   \n",
       "\n",
       "       average_total_equity_growth  cost_of_goods_sold_growth  \\\n",
       "count                 20413.000000               20413.000000   \n",
       "mean                      0.148603                   0.123439   \n",
       "std                       0.258743                   0.365712   \n",
       "min                      -0.992862                  -0.986064   \n",
       "25%                       0.026524                  -0.028507   \n",
       "50%                       0.099894                   0.081607   \n",
       "75%                       0.223167                   0.215812   \n",
       "max                       4.370252                  11.937225   \n",
       "\n",
       "       non_operating_revenue_growth  \n",
       "count                  20413.000000  \n",
       "mean                       0.211275  \n",
       "std                        0.664096  \n",
       "min                       -0.998892  \n",
       "25%                       -0.208175  \n",
       "50%                        0.107325  \n",
       "75%                        0.510184  \n",
       "max                        5.961739  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_selected = X[X.columns[selection_model.get_support()]]\n",
    "\n",
    "lr = LogisticRegression(penalty='l1',multi_class='ovr')\n",
    "lda = LinearDiscriminantAnalysis(solver='lsqr',shrinkage=True)\n",
    "gnb = GaussianNB()\n",
    "qda = QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
    "\n",
    "models = [lr, lda, qda, gnb]\n",
    "models_index = ['LR','LDA','QDA','GNB']\n",
    "scoring = ['accuracy','precision_macro','recall_macro','f1_macro']\n",
    "result = pd.DataFrame(columns=['variables','n_vars','method','accuracy','precision_macro','recall_macro','f1_macro'])\n",
    "\n",
    "cols=[]\n",
    "for i in X_selected.columns:\n",
    "    cols.append(i)\n",
    "    \n",
    "    X_new = X_selected[cols]\n",
    "    for count, model in enumerate(models):\n",
    "        score_dict ={}\n",
    "        score_dict['method'] = models_index[count]\n",
    "        score_dict['variables'] = ','.join(cols)\n",
    "        score_dict['n_vars'] = len(cols)\n",
    "        \n",
    "        for score in scoring:\n",
    "            scores = cross_val_score(model, X_new, y, cv=10, scoring=score)\n",
    "            score_dict[score] = np.mean(scores)\n",
    "        result = result.append(score_dict,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>n_vars</th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roe,dividends_to_assets</td>\n",
       "      <td>2.0</td>\n",
       "      <td>LDA</td>\n",
       "      <td>0.656595</td>\n",
       "      <td>0.69391</td>\n",
       "      <td>0.629624</td>\n",
       "      <td>0.610025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 variables  n_vars method  accuracy  precision_macro  \\\n",
       "5  roe,dividends_to_assets     2.0    LDA  0.656595          0.69391   \n",
       "\n",
       "   recall_macro  f1_macro  \n",
       "5      0.629624  0.610025  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['accuracy'] == max(result['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>n_vars</th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>roe,dividends_to_assets,short_term_borrowings_...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LDA</td>\n",
       "      <td>0.640182</td>\n",
       "      <td>0.639109</td>\n",
       "      <td>0.63429</td>\n",
       "      <td>0.63205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            variables  n_vars method  \\\n",
       "29  roe,dividends_to_assets,short_term_borrowings_...     8.0    LDA   \n",
       "\n",
       "    accuracy  precision_macro  recall_macro  f1_macro  \n",
       "29  0.640182         0.639109       0.63429   0.63205  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['f1_macro'] == max(result['f1_macro'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26a7b965278>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9EAAAFvCAYAAABNb0hfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26a7ba47b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.plot.bar(x=['method','n_vars'],y=['accuracy','precision_macro','recall_macro'],figsize=(12, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5493068142850145"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y=='DOWN'])/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[297   8   1 111  37   0 114  63   0   5]\n",
      " [199  22   1 278  73   0  61 124   5  69]\n",
      " [  3   0   0   5   1   0   0   0   0   2]\n",
      " [208   4   0 274  59   0 197  14   0  14]\n",
      " [175   3   0 241 130   0  57  27   0  29]\n",
      " [ 15   2   0  24   8   0  18   1   0   1]\n",
      " [  5   0   0   4   1   0  46   0   0   0]\n",
      " [ 71   4   0  20   5   0   7 198   1  31]\n",
      " [  0   0   0   0   0   0   5   3   4   0]\n",
      " [ 53   5   0  90  26   0  11  71   0  50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.13487828643968708, 'precision_weighted': 0.28903418282356924, 'recall_weighted': 0.13487828643968708}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y,test_size=0.33, random_state = 0)\n",
    "\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "\n",
    "# creating a confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, gnb_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision_weighted','recall_weighted']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(gnb, X, y, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844614784981161\n",
      "[[5607  226]\n",
      " [1433  431]]\n",
      "{'accuracy': 0.7792752350702677, 'recall_weighted': 0.7792752350702677, 'precision_weighted': 0.7583755131525948}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y2,test_size=0.33, random_state = 0)\n",
    "\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    " \n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)\n",
    " \n",
    "# creating a confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, gnb_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision_weighted','recall_weighted']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(gnb, X, y2, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327282579247\n",
      "[[189 133   0 183 109   0   0  22   0   0]\n",
      " [ 77 299   0 247 137   0   0  72   0   0]\n",
      " [  2   4   0   5   0   0   0   0   0   0]\n",
      " [104 157   0 395 111   0   0   3   0   0]\n",
      " [ 43 123   0 257 239   0   0   0   0   0]\n",
      " [  6  10   0  43  10   0   0   0   0   0]\n",
      " [  1   0   0  49   6   0   0   0   0   0]\n",
      " [ 35 186   0  16  15   0   0  85   0   0]\n",
      " [  0   0   0   5   0   0   0   7   0   0]\n",
      " [ 23 168   0  53  36   0   0  25   0   1]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-886024c91b9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'precision_macro'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'recall_macro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmul_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdict_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1581\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y,test_size=0.33, random_state = 0)\n",
    "\n",
    "mul_lr = LogisticRegression(multi_class='ovr')\n",
    "mul_lr.fit(X_train, y_train)\n",
    "\n",
    "mul_lr_predictions = mul_lr.predict(X_test)\n",
    "accuracy = mul_lr.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "cm = metrics.confusion_matrix(y_test, mul_lr_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision_macro','recall_macro']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(mul_lr, X, y, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-96dbf89997a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmul_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmul_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y2' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y2,test_size=0.33, random_state = 0)\n",
    "\n",
    "mul_lr = LogisticRegression(multi_class='ovr')\n",
    "mul_lr.fit(X_train, y_train)\n",
    "\n",
    "mul_lr_predictions = mul_lr.predict(X_test)\n",
    "accuracy = mul_lr.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "cm = metrics.confusion_matrix(y_test, mul_lr_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision','recall']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(mul_lr, X, y2, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387157951775\n",
      "[[253  64   2 174  98   0   8  35   1   1]\n",
      " [100 202   3 268 141   0  21  40   5  52]\n",
      " [  7   4   0   0   0   0   0   0   0   0]\n",
      " [172  72   1 383  91   3  38   4   2   4]\n",
      " [ 67  56   2 256 266   0  13   2   0   0]\n",
      " [  9   1   0  35  11   0  11   2   0   0]\n",
      " [  1   5   0  23   5   0  22   0   0   0]\n",
      " [ 65  24   1  18   3   0   0 220   0   6]\n",
      " [  0   0   0   5   0   0   0   0   7   0]\n",
      " [ 49  74   1  57  32   0   2  14   1  76]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.36322228864431899, 'recall_macro': 0.3126563480639995, 'precision_macro': 0.30809044873484642}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, random_state = 0)\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis(solver='lsqr').fit(X_train, y_train)\n",
    "LDA_predictions = lda_model.predict(X_test)\n",
    "\n",
    "accuracy = lda_model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "cm = metrics.confusion_matrix(y_test, LDA_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision_macro','recall_macro']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(lda_model, X, y, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-0344c7a9ddbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlda_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lsqr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLDA_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y2' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y2,test_size=0.33, random_state = 0)\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis(solver='lsqr').fit(X_train, y_train)\n",
    "LDA_predictions = lda_model.predict(X_test)\n",
    "\n",
    "accuracy = lda_model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "cm = metrics.confusion_matrix(y_test, LDA_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision','recall']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(lda_model, X, y2, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993768626389\n",
      "[[636   0   0   0   0   0   0   0   0   0]\n",
      " [  0 832   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  11   0   0   0   0   0]\n",
      " [  0   0   0 770   0   0   0   0   0   0]\n",
      " [  0   0   0   0 662   0   0   0   0   0]\n",
      " [  0   0   0   0   0  69   0   0   0   0]\n",
      " [  0   0   0   0   0   0  56   0   0   0]\n",
      " [  0   0   0   0   0   0   0 337   0   0]\n",
      " [  0   0   0   0  12   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 306]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:664: DeprecationWarning: 'store_covariances' was renamed to store_covariance in version 0.19 and will be removed in 0.21.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.0023243133250216929, 'recall_macro': 0.10000000000000001, 'precision_macro': 0.00023243133250216936}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, random_state = 0)\n",
    "\n",
    "qda_model = QuadraticDiscriminantAnalysis(store_covariances=True).fit(X_train, y_train)\n",
    "QDA_predictions = qda_model.predict(X_test)\n",
    "\n",
    "accuracy = qda_model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "cm = metrics.confusion_matrix(y_test, QDA_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision_macro','recall_macro']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(qda_model, X, y, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-09f98595aa97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mqda_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQuadraticDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore_covariances\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mQDA_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y2' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y2,test_size=0.33, random_state = 0)\n",
    "\n",
    "qda_model = QuadraticDiscriminantAnalysis(store_covariances=True).fit(X_train, y_train)\n",
    "QDA_predictions = qda_model.predict(X_test)\n",
    "\n",
    "accuracy = qda_model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "cm = metrics.confusion_matrix(y_test, QDA_predictions)\n",
    "print(cm)\n",
    "\n",
    "dict_score = {}\n",
    "scoring = ['accuracy','precision','recall']\n",
    "for score in scoring:\n",
    "    scores = cross_val_score(qda_model, X, y2, cv=10, scoring=score)\n",
    "    dict_score[score] = np.mean(scores)\n",
    "    \n",
    "print(dict_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rocku\\anaconda64\\lib\\site-packages\\ipykernel\\__main__.py:4: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('stat_data.csv', thousands=',',encoding = \"EUC-KR\")\n",
    "data2 = pd.read_csv('final!!!.csv', thousands=',', encoding = \"EUC-KR\")\n",
    "\n",
    "cols_to_use = data1.columns - data2.columns\n",
    "data_merged = pd.merge(data2, data1[cols_to_use],how='inner',left_on=['code','year'], right_on=['Symbol','Year'])\n",
    "data_merged = data_merged.drop(['code','year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.set_index(['Symbol','Year'],inplace=True)\n",
    "data_merged['next_roe'] = data_merged.groupby(level=0)['roe'].shift(-1)\n",
    "data_merged['updown'] = np.where(data_merged['roe'] < data_merged['next_roe'], 1,0)\n",
    "data_merged = data_merged[~data_merged.isin([np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_merged.dropna(axis=0, how='any')\n",
    "data_merged = data_merged[~ pd.isnull(data_merged)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_assets</th>\n",
       "      <th>total_liability</th>\n",
       "      <th>shorterm_debt</th>\n",
       "      <th>longterm_debt</th>\n",
       "      <th>total_equity</th>\n",
       "      <th>sales</th>\n",
       "      <th>cost_of_goods_sold</th>\n",
       "      <th>labor_cost</th>\n",
       "      <th>advertisement_cost</th>\n",
       "      <th>selling_cost</th>\n",
       "      <th>...</th>\n",
       "      <th>related_investment_assets</th>\n",
       "      <th>retained_earnings</th>\n",
       "      <th>retirement_pay</th>\n",
       "      <th>rnd_cost</th>\n",
       "      <th>self_equity</th>\n",
       "      <th>st_fin_assets</th>\n",
       "      <th>st_fin_liab</th>\n",
       "      <th>uncurrent_assets</th>\n",
       "      <th>next_roe</th>\n",
       "      <th>updown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">A005930</th>\n",
       "      <th>2000</th>\n",
       "      <td>2.689505e+10</td>\n",
       "      <td>1.104022e+10</td>\n",
       "      <td>8.608449e+09</td>\n",
       "      <td>2.093751e+09</td>\n",
       "      <td>1.619285e+10</td>\n",
       "      <td>3.428375e+10</td>\n",
       "      <td>2.199338e+10</td>\n",
       "      <td>5.181662e+08</td>\n",
       "      <td>6.511878e+08</td>\n",
       "      <td>9.383357e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.075443e+10</td>\n",
       "      <td>35441860.0</td>\n",
       "      <td>1.335400e+09</td>\n",
       "      <td>-9.622479e+08</td>\n",
       "      <td>2.093151e+09</td>\n",
       "      <td>2.369431e+09</td>\n",
       "      <td>1.913861e+10</td>\n",
       "      <td>0.151329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2.791941e+10</td>\n",
       "      <td>9.573928e+09</td>\n",
       "      <td>6.314242e+09</td>\n",
       "      <td>2.131415e+09</td>\n",
       "      <td>1.947375e+10</td>\n",
       "      <td>3.238037e+10</td>\n",
       "      <td>2.451473e+10</td>\n",
       "      <td>5.800693e+08</td>\n",
       "      <td>7.155440e+08</td>\n",
       "      <td>1.411229e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.335299e+10</td>\n",
       "      <td>49054259.0</td>\n",
       "      <td>1.552989e+09</td>\n",
       "      <td>-9.622479e+08</td>\n",
       "      <td>1.837655e+09</td>\n",
       "      <td>9.709419e+08</td>\n",
       "      <td>2.116380e+10</td>\n",
       "      <td>0.280511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>3.443960e+10</td>\n",
       "      <td>8.873158e+09</td>\n",
       "      <td>7.590014e+09</td>\n",
       "      <td>1.710645e+09</td>\n",
       "      <td>2.513894e+10</td>\n",
       "      <td>3.981311e+10</td>\n",
       "      <td>2.630056e+10</td>\n",
       "      <td>7.463130e+08</td>\n",
       "      <td>9.671370e+08</td>\n",
       "      <td>9.573790e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>6.548942e+09</td>\n",
       "      <td>2.032072e+10</td>\n",
       "      <td>77776000.0</td>\n",
       "      <td>1.759791e+09</td>\n",
       "      <td>-2.462091e+09</td>\n",
       "      <td>6.019915e+09</td>\n",
       "      <td>4.389860e+08</td>\n",
       "      <td>2.237102e+10</td>\n",
       "      <td>0.202587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>3.920338e+10</td>\n",
       "      <td>9.544782e+09</td>\n",
       "      <td>9.191898e+09</td>\n",
       "      <td>5.970080e+08</td>\n",
       "      <td>2.941448e+10</td>\n",
       "      <td>4.358202e+10</td>\n",
       "      <td>2.951875e+10</td>\n",
       "      <td>7.356010e+08</td>\n",
       "      <td>9.813460e+08</td>\n",
       "      <td>1.192303e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>6.610632e+09</td>\n",
       "      <td>2.440971e+10</td>\n",
       "      <td>51003000.0</td>\n",
       "      <td>2.017298e+09</td>\n",
       "      <td>-3.457834e+09</td>\n",
       "      <td>6.773397e+09</td>\n",
       "      <td>1.045211e+09</td>\n",
       "      <td>2.572097e+10</td>\n",
       "      <td>0.313200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>4.381654e+10</td>\n",
       "      <td>9.582520e+09</td>\n",
       "      <td>8.720903e+09</td>\n",
       "      <td>6.552310e+08</td>\n",
       "      <td>3.444041e+10</td>\n",
       "      <td>5.763236e+10</td>\n",
       "      <td>3.727969e+10</td>\n",
       "      <td>9.576620e+08</td>\n",
       "      <td>6.550300e+08</td>\n",
       "      <td>1.656797e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>8.353211e+09</td>\n",
       "      <td>3.057504e+10</td>\n",
       "      <td>61690000.0</td>\n",
       "      <td>2.687418e+09</td>\n",
       "      <td>-4.159639e+09</td>\n",
       "      <td>6.539900e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.985805e+10</td>\n",
       "      <td>0.192659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>5.053877e+10</td>\n",
       "      <td>1.012915e+10</td>\n",
       "      <td>8.345275e+09</td>\n",
       "      <td>2.536885e+09</td>\n",
       "      <td>3.965661e+10</td>\n",
       "      <td>5.745767e+10</td>\n",
       "      <td>4.015815e+10</td>\n",
       "      <td>8.980760e+08</td>\n",
       "      <td>1.069387e+09</td>\n",
       "      <td>1.710866e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>8.891880e+09</td>\n",
       "      <td>3.736589e+10</td>\n",
       "      <td>81736000.0</td>\n",
       "      <td>3.133216e+09</td>\n",
       "      <td>-5.970778e+09</td>\n",
       "      <td>5.882984e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.722314e+10</td>\n",
       "      <td>0.175153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>5.780913e+10</td>\n",
       "      <td>1.174685e+10</td>\n",
       "      <td>9.635015e+09</td>\n",
       "      <td>2.976529e+09</td>\n",
       "      <td>4.519758e+10</td>\n",
       "      <td>5.897276e+10</td>\n",
       "      <td>4.235975e+10</td>\n",
       "      <td>8.413400e+08</td>\n",
       "      <td>1.515037e+09</td>\n",
       "      <td>1.532289e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.126508e+10</td>\n",
       "      <td>4.435677e+10</td>\n",
       "      <td>86522000.0</td>\n",
       "      <td>3.302337e+09</td>\n",
       "      <td>-7.520023e+09</td>\n",
       "      <td>5.498185e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.425038e+10</td>\n",
       "      <td>0.144006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>6.522525e+10</td>\n",
       "      <td>1.313809e+10</td>\n",
       "      <td>1.080235e+10</td>\n",
       "      <td>2.862282e+09</td>\n",
       "      <td>5.156062e+10</td>\n",
       "      <td>6.317597e+10</td>\n",
       "      <td>4.684655e+10</td>\n",
       "      <td>9.187020e+08</td>\n",
       "      <td>1.446819e+09</td>\n",
       "      <td>1.763682e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500846e+10</td>\n",
       "      <td>5.096268e+10</td>\n",
       "      <td>103584000.0</td>\n",
       "      <td>3.411585e+09</td>\n",
       "      <td>-9.157492e+09</td>\n",
       "      <td>5.952842e+09</td>\n",
       "      <td>4.470000e+06</td>\n",
       "      <td>4.984581e+10</td>\n",
       "      <td>0.095088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>7.251922e+10</td>\n",
       "      <td>1.403518e+10</td>\n",
       "      <td>1.172136e+10</td>\n",
       "      <td>2.684368e+09</td>\n",
       "      <td>5.811349e+10</td>\n",
       "      <td>7.295299e+10</td>\n",
       "      <td>5.538060e+10</td>\n",
       "      <td>9.551810e+08</td>\n",
       "      <td>2.574215e+09</td>\n",
       "      <td>2.788310e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039019e+10</td>\n",
       "      <td>5.541605e+10</td>\n",
       "      <td>88954000.0</td>\n",
       "      <td>3.783958e+09</td>\n",
       "      <td>-8.910135e+09</td>\n",
       "      <td>4.407242e+09</td>\n",
       "      <td>6.009000e+06</td>\n",
       "      <td>5.609533e+10</td>\n",
       "      <td>0.133623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1.121798e+11</td>\n",
       "      <td>4.075564e+10</td>\n",
       "      <td>3.420442e+10</td>\n",
       "      <td>4.930163e+09</td>\n",
       "      <td>7.304520e+10</td>\n",
       "      <td>1.363237e+11</td>\n",
       "      <td>9.459486e+10</td>\n",
       "      <td>2.732159e+09</td>\n",
       "      <td>3.173900e+09</td>\n",
       "      <td>9.191900e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.334705e+09</td>\n",
       "      <td>7.106525e+10</td>\n",
       "      <td>113936000.0</td>\n",
       "      <td>7.386712e+09</td>\n",
       "      <td>-8.404791e+09</td>\n",
       "      <td>1.073353e+10</td>\n",
       "      <td>8.014334e+09</td>\n",
       "      <td>5.796849e+10</td>\n",
       "      <td>0.180713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              total_assets  total_liability  shorterm_debt  longterm_debt  \\\n",
       "Symbol  Year                                                                \n",
       "A005930 2000  2.689505e+10     1.104022e+10   8.608449e+09   2.093751e+09   \n",
       "        2001  2.791941e+10     9.573928e+09   6.314242e+09   2.131415e+09   \n",
       "        2002  3.443960e+10     8.873158e+09   7.590014e+09   1.710645e+09   \n",
       "        2003  3.920338e+10     9.544782e+09   9.191898e+09   5.970080e+08   \n",
       "        2004  4.381654e+10     9.582520e+09   8.720903e+09   6.552310e+08   \n",
       "        2005  5.053877e+10     1.012915e+10   8.345275e+09   2.536885e+09   \n",
       "        2006  5.780913e+10     1.174685e+10   9.635015e+09   2.976529e+09   \n",
       "        2007  6.522525e+10     1.313809e+10   1.080235e+10   2.862282e+09   \n",
       "        2008  7.251922e+10     1.403518e+10   1.172136e+10   2.684368e+09   \n",
       "        2009  1.121798e+11     4.075564e+10   3.420442e+10   4.930163e+09   \n",
       "\n",
       "              total_equity         sales  cost_of_goods_sold    labor_cost  \\\n",
       "Symbol  Year                                                                 \n",
       "A005930 2000  1.619285e+10  3.428375e+10        2.199338e+10  5.181662e+08   \n",
       "        2001  1.947375e+10  3.238037e+10        2.451473e+10  5.800693e+08   \n",
       "        2002  2.513894e+10  3.981311e+10        2.630056e+10  7.463130e+08   \n",
       "        2003  2.941448e+10  4.358202e+10        2.951875e+10  7.356010e+08   \n",
       "        2004  3.444041e+10  5.763236e+10        3.727969e+10  9.576620e+08   \n",
       "        2005  3.965661e+10  5.745767e+10        4.015815e+10  8.980760e+08   \n",
       "        2006  4.519758e+10  5.897276e+10        4.235975e+10  8.413400e+08   \n",
       "        2007  5.156062e+10  6.317597e+10        4.684655e+10  9.187020e+08   \n",
       "        2008  5.811349e+10  7.295299e+10        5.538060e+10  9.551810e+08   \n",
       "        2009  7.304520e+10  1.363237e+11        9.459486e+10  2.732159e+09   \n",
       "\n",
       "              advertisement_cost  selling_cost   ...    \\\n",
       "Symbol  Year                                     ...     \n",
       "A005930 2000        6.511878e+08  9.383357e+08   ...     \n",
       "        2001        7.155440e+08  1.411229e+09   ...     \n",
       "        2002        9.671370e+08  9.573790e+08   ...     \n",
       "        2003        9.813460e+08  1.192303e+09   ...     \n",
       "        2004        6.550300e+08  1.656797e+09   ...     \n",
       "        2005        1.069387e+09  1.710866e+09   ...     \n",
       "        2006        1.515037e+09  1.532289e+09   ...     \n",
       "        2007        1.446819e+09  1.763682e+09   ...     \n",
       "        2008        2.574215e+09  2.788310e+09   ...     \n",
       "        2009        3.173900e+09  9.191900e+09   ...     \n",
       "\n",
       "              related_investment_assets  retained_earnings  retirement_pay  \\\n",
       "Symbol  Year                                                                 \n",
       "A005930 2000               0.000000e+00       1.075443e+10      35441860.0   \n",
       "        2001               0.000000e+00       1.335299e+10      49054259.0   \n",
       "        2002               6.548942e+09       2.032072e+10      77776000.0   \n",
       "        2003               6.610632e+09       2.440971e+10      51003000.0   \n",
       "        2004               8.353211e+09       3.057504e+10      61690000.0   \n",
       "        2005               8.891880e+09       3.736589e+10      81736000.0   \n",
       "        2006               1.126508e+10       4.435677e+10      86522000.0   \n",
       "        2007               1.500846e+10       5.096268e+10     103584000.0   \n",
       "        2008               2.039019e+10       5.541605e+10      88954000.0   \n",
       "        2009               7.334705e+09       7.106525e+10     113936000.0   \n",
       "\n",
       "                  rnd_cost   self_equity  st_fin_assets   st_fin_liab  \\\n",
       "Symbol  Year                                                            \n",
       "A005930 2000  1.335400e+09 -9.622479e+08   2.093151e+09  2.369431e+09   \n",
       "        2001  1.552989e+09 -9.622479e+08   1.837655e+09  9.709419e+08   \n",
       "        2002  1.759791e+09 -2.462091e+09   6.019915e+09  4.389860e+08   \n",
       "        2003  2.017298e+09 -3.457834e+09   6.773397e+09  1.045211e+09   \n",
       "        2004  2.687418e+09 -4.159639e+09   6.539900e+09  0.000000e+00   \n",
       "        2005  3.133216e+09 -5.970778e+09   5.882984e+09  0.000000e+00   \n",
       "        2006  3.302337e+09 -7.520023e+09   5.498185e+09  0.000000e+00   \n",
       "        2007  3.411585e+09 -9.157492e+09   5.952842e+09  4.470000e+06   \n",
       "        2008  3.783958e+09 -8.910135e+09   4.407242e+09  6.009000e+06   \n",
       "        2009  7.386712e+09 -8.404791e+09   1.073353e+10  8.014334e+09   \n",
       "\n",
       "              uncurrent_assets  next_roe  updown  \n",
       "Symbol  Year                                      \n",
       "A005930 2000      1.913861e+10  0.151329       0  \n",
       "        2001      2.116380e+10  0.280511       1  \n",
       "        2002      2.237102e+10  0.202587       0  \n",
       "        2003      2.572097e+10  0.313200       1  \n",
       "        2004      2.985805e+10  0.192659       0  \n",
       "        2005      3.722314e+10  0.175153       0  \n",
       "        2006      4.425038e+10  0.144006       0  \n",
       "        2007      4.984581e+10  0.095088       0  \n",
       "        2008      5.609533e+10  0.133623       1  \n",
       "        2009      5.796849e+10  0.180713       1  \n",
       "\n",
       "[10 rows x 65 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['average_total_assets', 'average_total_equity', 'sales', 'roe',\n",
       "       'dividends_to_assets', 'cash_and_cash_equivalents_to_assets',\n",
       "       'short_term_financial_assets_to_assets',\n",
       "       'accounts_and_other_receivables_to_assets', 'inventories_to_assets',\n",
       "       'non_current_assets_as_held_for_sale_to_assets',\n",
       "       'long_term_financial_assets_to_assets', 'tangible_assets_to_assets',\n",
       "       'land_to_assets', 'facility_assets_to_assets',\n",
       "       'other_tangible_assets_to_assets',\n",
       "       'assets_under_construction_to_assets', 'intangible_assets_to_assets',\n",
       "       'goodwill_to_assets', 'long_term_sales_and_other_receivables_to_assets',\n",
       "       'accounts_and_other_payables_to_assets',\n",
       "       'short_term_borrowings_to_assets',\n",
       "       'current_portion_of_long_term_debts_to_assets',\n",
       "       'short_term_provisions_to_assets', 'general_bonds_to_assets',\n",
       "       'convertible_bonds_to_assets', 'bonds_with_warrents_to_assets',\n",
       "       'long_term_borrowings_to_assets',\n",
       "       'financial_lease_liabilities_to_assets',\n",
       "       'longterm_accounts_and_other_payables_to_assets',\n",
       "       'controlling_equity_to_assets', 'common_stock_capital_to_assets',\n",
       "       'preferred_stock_capital_to_assets',\n",
       "       'paid_in_capital_in_excess_of_par_value_to_assets',\n",
       "       'other_capital_surplus_to_assets', 'treasury_stock_to_assets',\n",
       "       'retained_earnings_to_assets', 'cost_of_goods_sold_to_sales',\n",
       "       'labor_costs_to_sales', 'tangible_depreciation_costs_to_sales',\n",
       "       'intangible_depreciation_costs_to_sales', 'rnd_costs_to_sales',\n",
       "       'advertisement_cost_to_sales', 'rent_to_sales',\n",
       "       'taxes and dues_to_sales', 'non_operating_revenue_to_sales',\n",
       "       'non_operating_expenses_to_sales',\n",
       "       'continuing_income_before_taxes_to_sales',\n",
       "       'taxes_from_continuing_operation_to_sales',\n",
       "       'discontinued_income_to_sales', 'operating_cash_flow_to_cashflow',\n",
       "       'investing_cash_flow_to_cashflow', 'financing_cash_flow_to_cashflow',\n",
       "       'average_total_equity_growth', 'sales_growth',\n",
       "       'cost_of_goods_sold_growth', 'sna_expenses_growth',\n",
       "       'non_operating_revenue_growth', 'non_operating_expenses_growth',\n",
       "       'sector', 'future_roe', 'roe_class', 'next_roe', 'updown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# data_norm = data_merged[['total_assets', 'total_liability', 'shorterm_debt', 'longterm_debt',\n",
    "#                         'total_equity', 'sales', 'cost_of_goods_sold', 'labor_cost',\n",
    "#                         'advertisement_cost', 'selling_cost', 'administrative cost',\n",
    "#                         'dividends', 'net_income', 'sales_growth', 'roe',\n",
    "#                         'cost_of_goods_sold_growth', 'labor_cost_growth',\n",
    "#                         'advertisement_cost_growth', 'selling_cost_growth',\n",
    "#                         'administrative cost_growth', 'dividends_growth', 'stdebt_ratio',\n",
    "#                         'ltdebt_ratio', 'debt_ratio', 'shorterm_debt_growth',\n",
    "#                         'longterm_debt_growth', 'cost_of_goods_sold_ratio', 'labor_cost_ratio',\n",
    "#                         'advertisement_cost_ratio', 'selling_cost_ratio',\n",
    "#                         'administrative cost_ratio', 'acc_liab', 'acc_receivble',\n",
    "#                         'ad_cost', 'admin_cost', 'afs_fin_assets', 'borrowing_cost', 'cash_eq',\n",
    "#                         'cash_flow', 'cogs', 'cont_equity', 'cont_net_income', 'dividends.1',\n",
    "#                         'facility', 'ing_assets', 'interest_expense', 'interest_revenue',\n",
    "#                         'inventory', 'land', 'lt_acc_receivable', 'lt_fin_assets',\n",
    "#                         'lt_fin_liab', 'other_employee_benefits?', 'payward',\n",
    "#                         'related_investment_assets', 'retained_earnings', 'retirement_pay',\n",
    "#                         'rnd_cost', 'self_equity', 'st_fin_assets', 'st_fin_liab',\n",
    "#                         'uncurrent_assets']]\n",
    "# np_scaled = min_max_scaler.fit_transform(data_norm)\n",
    "# X = pd.DataFrame(np_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = data_merged[data_merged['net_income'] < 0]\n",
    "\n",
    "data_dummy = pd.get_dummies(dataf['sector'])\n",
    "data_merged2 = pd.merge(dataf.reset_index(),data_dummy.reset_index(), how='inner', on=['Symbol','Year'])\n",
    "data = data_merged2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76211782252050708"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.reset_index().drop(['Symbol','Year','sector','updown','next_roe'], axis=1)\n",
    "y = data['updown'].astype(np.float64)\n",
    "\n",
    "clf_l1_LR = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "clf_l1_LR.fit(np.array(X), np.array(y))\n",
    "clf_l1_LR.score(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0\n",
      "STEP 12\n",
      "STEP 24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-29018d52184e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf_l1_LR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclf_l1_LR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_l1_LR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1152\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 self.max_iter, self.tol, self.random_state)\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         epsilon)\n\u001b[0m\u001b[1;32m    917\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_origin = data.reset_index().drop(['Symbol','Year','sector','updown'], axis=1)\n",
    "score = []\n",
    "for i in range(5):\n",
    "    print('STEP', str(i*12))\n",
    "    X = data_origin.iloc[:,:i*12+1]\n",
    "    y = data_merged['updown'].astype(np.float64)\n",
    "\n",
    "    clf_l1_LR = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "    clf_l1_LR.fit(np.array(X), np.array(y))\n",
    "    score.append(clf_l1_LR.score(np.array(X), np.array(y)))\n",
    "    \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4906 6252\n"
     ]
    }
   ],
   "source": [
    "print(len(data[data['updown'] == 1]), len(data[data['updown'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-52a0105da7cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_l1_LR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1433\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1152\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 self.max_iter, self.tol, self.random_state)\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\rocku\\anaconda64\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         epsilon)\n\u001b[0m\u001b[1;32m    917\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf_l1_LR, X, y, cv=10, scoring='f1_macro')\n",
    "print(scores)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predicted'] = clf_l1_LR.predict(np.array(X))\n",
    "data.to_csv('predicted2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_l1_SVM = svm.SVC(C=0.84, tol=0.001, verbose=False, kernel='rbf')\n",
    "clf_l1_SVM.fit(np.array(X), np.array(y))\n",
    "clf_l1_SVM.score(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_l1_SVM, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-337-b8883e3d40e4>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-337-b8883e3d40e4>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    from keras.regularizers\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9817, 64)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7853 samples, validate on 1964 samples\n",
      "Epoch 1/10\n",
      "7853/7853 [==============================] - 1s 147us/step - loss: 5093603.4193 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 2/10\n",
      "7853/7853 [==============================] - 0s 24us/step - loss: 5093603.3411 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 3/10\n",
      "7853/7853 [==============================] - 0s 25us/step - loss: 5093603.4654 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 4/10\n",
      "7853/7853 [==============================] - 0s 24us/step - loss: 5093603.3893 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 5/10\n",
      "7853/7853 [==============================] - 0s 25us/step - loss: 5093603.2630 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 6/10\n",
      "7853/7853 [==============================] - 0s 28us/step - loss: 5093603.3623 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 7/10\n",
      "7853/7853 [==============================] - 0s 27us/step - loss: 5093603.4750 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 8/10\n",
      "7853/7853 [==============================] - 0s 25us/step - loss: 5093603.5141 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 9/10\n",
      "7853/7853 [==============================] - 0s 24us/step - loss: 5093603.3098 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n",
      "Epoch 10/10\n",
      "7853/7853 [==============================] - 0s 25us/step - loss: 5093603.4932 - acc: 0.9124 - val_loss: 2036674.1589 - val_acc: 0.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f5eef5a7b8>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = 64\n",
    "\n",
    "input_words = Input(shape=(input_length,))\n",
    "l1 = Dense(200, activation='relu')(input_words)\n",
    "l2 = Dense(100, activation='relu')(l1)\n",
    "l3 = Dense(50, activation='relu')(l2)\n",
    "l4 = Dense(10, activation='relu')(l3)\n",
    "ouput = Dense(1, activation='sigmoid')(l4)\n",
    "\n",
    "nn_model = Model(input_words, ouput)\n",
    "nn_model.compile(loss='mape', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "total_samples = X.shape[0]\n",
    "train_samples = int(round(7*total_samples/10,0))\n",
    "x_train = X.values[:train_samples]\n",
    "y_train = y.values[:train_samples]\n",
    "x_test = X.values[train_samples+1:]\n",
    "y_test = y.values[train_samples+1:]\n",
    "\n",
    "nn_model.fit(X.values, y.values,\n",
    "                epochs=10,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9817/9817 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4482030.487929103, 0.90129367426892359]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.evaluate(x=X.values,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
