{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full insert by using .to_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://**.rds.amazonaws.com:5432/**')\n",
    "conn = engine.connect()\n",
    "\n",
    "price_data.to_sql(name='comp_price', con=engine, if_exists = 'replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .to_sql insert by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://**.rds.amazonaws.com:5432/**')\n",
    "chunks = pd.read_csv('adj_prices.csv', chunksize=1000)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(i)\n",
    "    chunk['shcode'] = chunk['code'].str[1:]\n",
    "    chunk.drop('code', axis=1, inplace=True)\n",
    "    chunk.to_sql(name='comp_price', con=engine, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw level bulk insert\n",
    "\n",
    "- Much Much Faster than the .to_sql function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  load data completed\n",
      "1  load data completed\n",
      "2  load data completed\n",
      "3  load data completed\n",
      "4  load data completed\n",
      "5  load data completed\n",
      "6  load data completed\n",
      "7  load data completed\n",
      "8  load data completed\n",
      "9  load data completed\n",
      "10  load data completed\n",
      "11  load data completed\n",
      "12  load data completed\n",
      "13  load data completed\n",
      "14  load data completed\n",
      "15  load data completed\n",
      "16  load data completed\n",
      "17  load data completed\n",
      "18  load data completed\n",
      "19  load data completed\n",
      "20  load data completed\n",
      "21  load data completed\n",
      "22  load data completed\n",
      "23  load data completed\n",
      "24  load data completed\n",
      "25  load data completed\n",
      "26  load data completed\n",
      "27  load data completed\n",
      "28  load data completed\n",
      "29  load data completed\n",
      "30  load data completed\n",
      "31  load data completed\n"
     ]
    }
   ],
   "source": [
    "conn_string = \"host='**' dbname ='**' user='**' password='**'\"\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "except:\n",
    "    print(\"error database connection\")\n",
    "\n",
    "curs = conn.cursor()\n",
    "\n",
    "\n",
    "chunks = pd.read_csv('adj_prices.csv', chunksize=100000)\n",
    "for i, df in enumerate(chunks):\n",
    "    df['dt'] = pd.to_datetime(df['dt'])\n",
    "    df['shcode'] = df['code'].str[1:]\n",
    "    sql_query = '''\n",
    "        INSERT INTO comp_price (date, shcode, open, high, low, close, volume)\n",
    "            SELECT unnest( %(dates)s),\n",
    "                   unnest( %(shcodes)s),\n",
    "                   unnest( %(opens)s),\n",
    "                   unnest( %(highs)s),\n",
    "                   unnest( %(lows)s),\n",
    "                   unnest( %(closes)s),\n",
    "                   unnest( %(volumes)s)\n",
    "        '''\n",
    "    \n",
    "    dataset = {}\n",
    "    dataset['dates'] = df['dt'].tolist()\n",
    "    dataset['shcodes'] = df['shcode'].tolist()\n",
    "    dataset['opens'] = df['adj_open'].tolist()\n",
    "    dataset['highs'] = df['adj_high'].tolist()\n",
    "    dataset['lows'] = df['adj_low'].tolist()\n",
    "    dataset['closes'] = df['adj_close'].tolist()\n",
    "    dataset['volumes'] = df['adj_volume'].tolist()\n",
    "    print(i, ' load data completed')\n",
    "\n",
    "    curs.execute(sql_query, dataset)\n",
    "    conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
